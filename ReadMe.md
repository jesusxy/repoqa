## repoqa

#### ðŸ§ª Workflow

```
# Index a repo (only once or after changes)
$ repoqa index ./typescript-go

âœ… Indexed 127 files, 1,600 code chunks.

# Ask questions about the repo
$ repoqa ask "How is type-checking handled in the parser?"

ðŸ§  Searching...
ðŸ§  Selecting top 3 chunks (3.2K tokens)
ðŸ§  Asking GPT-4...

ðŸ“Ž Answer:
The parser calls into `checker.go`, which recursively validates types using...
```

#### Repo Scaffold

```
repoqa/
â”œâ”€â”€ go_embed/
â”‚   â”œâ”€â”€ main.go          # CLI entrypoint
â”‚   â”œâ”€â”€ embed.go         # Embedding logic
â”‚   â”œâ”€â”€ search.go        # Cosine search logic
â”‚   â”œâ”€â”€ types.go
â”‚   â””â”€â”€ utils.go
â”œâ”€â”€ ask.ts               # Takes top chunks, prompts LLM
â”œâ”€â”€ summarizer.ts        # Prompt building logic
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ chunked.jsonl
â”‚   â””â”€â”€ .index.json

```

## ðŸ§  What I Learned

### Go Struct Tags

Tag format : `FieldName FieldType json:"jsonKeyName"`

- maps a Go field to a JSON key
- ensures compatibility even if names dont match exactly

Example: `Name string json:"user_name"` // maps JSON "user_name" to Go field Name`

### Vector Embeddings

This project deepened my understanding of how vector embeddings power semantic search and LLM-based tools:

- **Embeddings represent meaning** â€” I learned that OpenAI's `text-embedding-ada-002` model converts text/code into high-dimensional vectors that capture semantic relationships, not just keywords.
- **Chunks of code become coordinates** â€” Each code snippet is embedded as a 1536-dimensional vector, placing it in a conceptual space where similar functionality or intent lands nearby.
  > You can think of an embedding as the GPS coordinates of a thought in a high-dimensional space.
- **Semantic search enables smart retrieval** â€” Instead of relying on exact string matches, embeddings let us retrieve code that's relevant to a question based on meaning.
- **This mirrors real-world tools** â€” This is the same foundation used by tools like Sourcegraph Cody, GitHub Copilot, and ChatGPT when answering questions about large codebases.

Through building this pipeline in Go, I not only integrated an OpenAI API into a real-world tool but also came away with a stronger grasp of how LLMs and embeddings work together in production systems.
